{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorflowPrac20_writting_loop_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9vj7ZUFZkf0EpL8Uh/Vg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinaypatil-Ev/vinEvPy-GoCoLab/blob/main/Tensorflow/TensorflowPrac20_writting_loop_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skfQMLnxcX_Z"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmHLP_T_e8bt"
      },
      "source": [
        "def get_model():  \r\n",
        "    inputs = tf.keras.Input(shape=(784, ))\r\n",
        "    x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\r\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\r\n",
        "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\r\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrPT6gPHfZv7"
      },
      "source": [
        "(xtrn, ytrn), (xtst, ytst) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdGhFNZlglv2"
      },
      "source": [
        "xtrn = xtrn.reshape((-1, 784))\r\n",
        "xtst = xtst.reshape((-1, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6wm4n5Bit6f",
        "outputId": "0b04ec68-353c-4ac7-affe-0b956db259d0"
      },
      "source": [
        "xtrn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieoO-r_xgw6y"
      },
      "source": [
        "batch_size = 64\r\n",
        "trn_data = tf.data.Dataset.from_tensor_slices((xtrn, ytrn))\r\n",
        "trn_data = trn_data.shuffle(buffer_size=1024).batch(batch_size)\r\n",
        "tst_data = tf.data.Dataset.from_tensor_slices((xtst, ytst))\r\n",
        "tst_data = tst_data.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6nFqS37jUV7"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\r\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AmM4quKl9Hm"
      },
      "source": [
        "## Custom training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pEDvfbzlzqa",
        "outputId": "e2e138cb-2dc7-4c31-9cf9-78199c04cf19"
      },
      "source": [
        "epochs = 2\r\n",
        "model = get_model()\r\n",
        "for epoch in range(epochs):\r\n",
        "    print(f\"epoch{epoch}\")\r\n",
        "    for steps, (xtrn, ytrn) in enumerate(trn_data):\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            ypred = model(xtrn, training=True)\r\n",
        "            loss_value = loss_fn(ytrn, ypred)\r\n",
        "        grad = tape.gradient(loss_value, model.trainable_weights)\r\n",
        "        optimizer.apply_gradients(zip(grad, model.trainable_weights))\r\n",
        "\r\n",
        "        if steps % 100 == 0:\r\n",
        "            print(f\"batch {steps}\", \"Loss:\", float(loss_value))\r\n",
        "\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch0\n",
            "batch 0 Loss: 72.48542022705078\n",
            "batch 100 Loss: 1.882691502571106\n",
            "batch 200 Loss: 1.5710645914077759\n",
            "batch 300 Loss: 1.1366631984710693\n",
            "batch 400 Loss: 1.3355623483657837\n",
            "batch 500 Loss: 1.4733967781066895\n",
            "batch 600 Loss: 1.0884144306182861\n",
            "batch 700 Loss: 0.8246899247169495\n",
            "batch 800 Loss: 0.9663909673690796\n",
            "batch 900 Loss: 0.21262231469154358\n",
            "epoch1\n",
            "batch 0 Loss: 0.6532958745956421\n",
            "batch 100 Loss: 0.6560090780258179\n",
            "batch 200 Loss: 0.4853571057319641\n",
            "batch 300 Loss: 0.4727972149848938\n",
            "batch 400 Loss: 0.6853070259094238\n",
            "batch 500 Loss: 0.7546948194503784\n",
            "batch 600 Loss: 0.714614987373352\n",
            "batch 700 Loss: 0.3614707589149475\n",
            "batch 800 Loss: 0.6650391817092896\n",
            "batch 900 Loss: 0.25575166940689087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qrqLFQ5vqz9"
      },
      "source": [
        "## Training loop with metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_D_o2ppsgw_"
      },
      "source": [
        "model = get_model()\r\n",
        "batch_size = 64\r\n",
        "epochs = 4\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\r\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "acc_metrics = tf.keras.metrics.SparseCategoricalAccuracy()\r\n",
        "val_metrics = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgwIOLc10cW1"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4Ed1QD5w-EZ",
        "outputId": "68a76f82-f5ab-41d2-b0ff-6be57ddc5a55"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "    print(f\"epoch:{epoch}\")\r\n",
        "    start_time = time.time()\r\n",
        "    for steps, (xtrn, ytrn) in enumerate(trn_data):\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            pred = model(xtrn, training=True)\r\n",
        "            loss_value = loss_fn(ytrn, pred)\r\n",
        "        grad = tape.gradient(loss_value, model.trainable_weights)\r\n",
        "        optimizer.apply_gradients(zip(grad, model.trainable_weights))\r\n",
        "        acc_metrics.update_state(ytrn, pred)\r\n",
        "        # if steps % 100 == 0:\r\n",
        "            # print(f\"steps:{steps}\", \"loss\", loss_value) \r\n",
        "    trn_acc = acc_metrics.result()\r\n",
        "    print(\"accuracy %.4f\" % (float(trn_acc)))\r\n",
        "\r\n",
        "    acc_metrics.reset_states()\r\n",
        "\r\n",
        "    for xtst, ytst in tst_data:\r\n",
        "        pred = model(xtst)\r\n",
        "        val_metrics.update_state(ytst, pred)\r\n",
        "\r\n",
        "    val_acc = val_metrics.result()\r\n",
        "    print(\"val acc: %.4f\" % (float(val_acc)))\r\n",
        "    print(\"Time taken: %.2fs\" % (float(time.time() - start_time)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "accuracy 0.7286\n",
            "val acc: 0.8167\n",
            "Time taken: 7.34s\n",
            "epoch:1\n",
            "accuracy 0.8497\n",
            "val acc: 0.8449\n",
            "Time taken: 7.38s\n",
            "epoch:2\n",
            "accuracy 0.8810\n",
            "val acc: 0.8594\n",
            "Time taken: 7.22s\n",
            "epoch:3\n",
            "accuracy 0.8984\n",
            "val acc: 0.8687\n",
            "Time taken: 7.32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQrrVr_K12NC"
      },
      "source": [
        "## speed up with tf.function()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xszm2wJZ2OvN"
      },
      "source": [
        "model = get_model()\r\n",
        "batch_size = 64\r\n",
        "epochs = 4\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\r\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "acc_metrics = tf.keras.metrics.SparseCategoricalAccuracy()\r\n",
        "val_metrics = tf.keras.metrics.SparseCategoricalAccuracy()\r\n",
        "model = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiZBZTvpxEkJ"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(x, y):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        pred = model(x, training=True)\r\n",
        "        loss_value = loss_fn(ytrn, pred)\r\n",
        "    grad = tape.gradient(loss_value, model.trainable_weights)\r\n",
        "    optimizer.apply_gradients(zip(grad, model.trainable_weights))\r\n",
        "    acc_metrics.update_state(ytrn, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oyeQ_rR3OHR"
      },
      "source": [
        "@tf.function\r\n",
        "def test_step(x, y):\r\n",
        "    pred = model(x)\r\n",
        "    val_metrics.update_state(y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlpsKPBf3nvG",
        "outputId": "95040205-bc74-4fe4-e96d-0b98a4790a24"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "    print(f\"epoch: {epoch}\")\r\n",
        "    start_time = time.time()\r\n",
        "    for steps, (xtrn, ytrn) in enumerate(trn_data):\r\n",
        "        train_step(xtrn, ytrn)\r\n",
        "    trn_acc = acc_metrics.result()\r\n",
        "    print(\"trn_acc: %.4f\" % (trn_acc))\r\n",
        "    for xtst, ytst in tst_data:\r\n",
        "        test_step(xtst, ytst)\r\n",
        "    val_acc = val_metrics.result()\r\n",
        "    print(\"val_acc: %.4f\" % (val_acc))   \r\n",
        "    print(\"Time Taken: %.2fS\" % (time.time() - start_time)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "trn_acc: 0.1632\n",
            "val_acc: 0.0950\n",
            "Time Taken: 2.28S\n",
            "epoch: 1\n",
            "trn_acc: 0.1670\n",
            "val_acc: 0.0951\n",
            "Time Taken: 1.81S\n",
            "epoch: 2\n",
            "trn_acc: 0.1684\n",
            "val_acc: 0.0952\n",
            "Time Taken: 1.70S\n",
            "epoch: 3\n",
            "trn_acc: 0.1691\n",
            "val_acc: 0.0952\n",
            "Time Taken: 1.68S\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK4S90o8paxf"
      },
      "source": [
        "## End to End network with Gan Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLtF2Yii6dmu"
      },
      "source": [
        "descriminator = tf.keras.Sequential([\r\n",
        "    tf.keras.Input((28, 28, 1)),\r\n",
        "    tf.keras.layers.Conv2D(64, 3, (2, 2), padding=\"same\"),\r\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n",
        "    tf.keras.layers.Conv2D(128, 3, (2, 2), padding=\"same\"),\r\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n",
        "    tf.keras.layers.Dense(1),\r\n",
        "], name=\"Descrimintor\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEC-ZwdVkmnY"
      },
      "source": [
        "latent_dim = 128\r\n",
        "generator = tf.keras.Sequential([\r\n",
        "    tf.keras.Input(shape=(latent_dim,)),\r\n",
        "    tf.keras.layers.Dense(7 * 7 * 128),\r\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n",
        "    tf.keras.layers.Reshape((7, 7, 128)),\r\n",
        "    tf.keras.layers.Conv2DTranspose(128, 4, (2, 2), padding=\"same\"),\r\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n",
        "    tf.keras.layers.Conv2DTranspose(128, 4, (2, 2), padding=\"same\"),\r\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n",
        "    tf.keras.layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\")\r\n",
        "], name=\"Generator\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7zrs8NOnZDj"
      },
      "source": [
        "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.003, name=\"d_opti\")\r\n",
        "g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.003, name=\"g_opti\")\r\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, name=\"loss_fn\")\r\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM0o9mgCp4ud"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(real_img):\r\n",
        "    random_latent_vector = tf.random.normal((batch_size, latent_dim), name=\"rlv1\")\r\n",
        "    gen_img = generator(random_latent_vector)\r\n",
        "    combined_img = tf.concat([gen_img, real_img], axis=0)\r\n",
        "    labels = tf.concat([\r\n",
        "                        tf.ones((batch_size, 1)),\r\n",
        "                        tf.zeros((real_img.shape[0], 1)),], axis=0)\r\n",
        "    labels += 0.05 * tf.random.uniform(labels.shape, name=\"label_0\")\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        pred = descriminator(combined_img)\r\n",
        "        d_loss_value = loss_fn(labels, pred)\r\n",
        "    grad = tape.gradient(d_loss_value, descriminator.trainable_weights)\r\n",
        "    d_optimizer.apply_gradients(zip(grad, descriminator.trainable_weights))\r\n",
        "\r\n",
        "    random_latent_vector = tf.random.normal(shape=(batch_size, latent_dim), name=\"rlv2\")\r\n",
        "    false_labels = tf.zeros((batch_size, 1), name=\"false_label_0\")\r\n",
        "\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        pred = descriminator(generator(random_latent_vector))\r\n",
        "        g_loss_value = loss_fn(false_labels, pred)\r\n",
        "    grad = tape.gradient(g_loss_value, generator.trainable_weights)\r\n",
        "    g_optimizer.apply_gradients(grad, generator.trainable_weights)\r\n",
        "\r\n",
        "    return d_loss_value, g_loss_value, gen_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDRzhTIIuowk"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCiOTCtRwMWC"
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZoX--iZvab6"
      },
      "source": [
        "(xtrn, _), (xtst, _) = tf.keras.datasets.mnist.load_data()\r\n",
        "x = np.concatenate([xtrn, xtst])\r\n",
        "x = x.astype(\"float32\") / 255.0\r\n",
        "x = x.reshape((-1, 28, 28, 1))\r\n",
        "data = tf.data.Dataset.from_tensor_slices(x)\r\n",
        "data = data.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BvUvY2Wx-qG"
      },
      "source": [
        "epochs = 1\r\n",
        "save_dir = \"./\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "eK4JocCtyGvT",
        "outputId": "ee23bb6e-f823-4c1a-f12b-a6fc96e2465f"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "    for steps, real_img in enumerate(data):\r\n",
        "        d_loss, g_loss, gen_img = train_step(real_img)\r\n",
        "        if steps % 200 == 0:\r\n",
        "            print(f\"d_loss {float(d_loss)}\")\r\n",
        "            print(f\"g_loss {float(g_loss)} \")\r\n",
        "            img = tf.keras.preprocessing.image.array_to_img(\r\n",
        "                gen_img[0] * 255.0, scale=False\r\n",
        "            )\r\n",
        "            img.save(os.path.join(save_dir, \"gen_img\" + str(step) + \".png\"))\r\n",
        "        if step > 1:\r\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-0eff78a79f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"d_loss {float(d_loss)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-157-bc6cddef9d4e>:12 train_step  *\n        d_loss_value = loss_fn(labels, pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:152 __call__  **\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4979 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((128, 7, 7, 1) vs (128, 1))\n"
          ]
        }
      ]
    }
  ]
}